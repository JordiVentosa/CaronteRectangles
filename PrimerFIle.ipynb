{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:21:59.331756: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-26 16:21:59.332319: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-26 16:21:59.334876: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-26 16:21:59.342589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1729952519.356840   34319 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1729952519.360281   34319 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-26 16:21:59.374905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spark\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['activitat_id', 'activitat', 'aula_id', 'startdate', 'duedate',\n",
      "       'grade'],\n",
      "      dtype='object')\n",
      "   activitat_id                                activitat  aula_id  startdate  \\\n",
      "0             3            Problema 1.1 - Hello world!!!       87          0   \n",
      "1             4         Problema 1.2 - Hello world!!! ++       87          0   \n",
      "2             5               Problema 3a.1: C�lcul edat       87          0   \n",
      "3             6  Problema 3a.8: Conversi� d�lars a euros       87          0   \n",
      "4             7         Problema 3a.11: Mitjana de notes       87          0   \n",
      "\n",
      "   duedate  grade  \n",
      "0        0    100  \n",
      "1        0    100  \n",
      "2        0    100  \n",
      "3        0    100  \n",
      "4        0    100  \n"
     ]
    }
   ],
   "source": [
    "#read the data\n",
    "\n",
    "activitats = pd.read_csv('data/activitats.csv')\n",
    "notes = pd.read_csv('data/notes.csv')\n",
    "trameses = pd.read_csv('data/trameses.csv')\n",
    "\n",
    "#show the columns\n",
    "\n",
    "print(activitats.columns)\n",
    "\n",
    "#show the first 5 rows\n",
    "\n",
    "print(activitats.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencem treient totes les activitats que no tenen cap tramesa associada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   activitat_id                                activitat  aula_id  startdate  \\\n",
      "0             3            Problema 1.1 - Hello world!!!       87          0   \n",
      "1             4         Problema 1.2 - Hello world!!! ++       87          0   \n",
      "2             5               Problema 3a.1: C�lcul edat       87          0   \n",
      "3             6  Problema 3a.8: Conversi� d�lars a euros       87          0   \n",
      "4             7         Problema 3a.11: Mitjana de notes       87          0   \n",
      "\n",
      "   duedate  grade  \n",
      "0        0    100  \n",
      "1        0    100  \n",
      "2        0    100  \n",
      "3        0    100  \n",
      "4        0    100  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter activitats to keep only entries with an activitat_id present in trameses\n",
    "activitats_filtered = activitats[activitats['activitat_id'].isin(trameses['activitat_id'].unique())]\n",
    "\n",
    "# Save or display the filtered activitats DataFrame\n",
    "activitats_filtered.to_csv('activitats_filtered.csv', index=False)\n",
    "print(activitats_filtered.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuació afegim una clau shared_id que s'encarrega de relacionar tasques identiques que es troben a cursos diferents les que no pertanyen a cap d'aquestses classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34319/3240484575.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  activitats_filtered['shared_id'] = activitats_filtered['activitat'].map(activitat_unique_id)\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map each unique activitat to a unique ID\n",
    "activitat_unique_id = {activitats_filtered: idx for idx, activitats_filtered in enumerate(activitats_filtered['activitat'].unique(), start=1)}\n",
    "\n",
    "# Map the activitat values to the unique IDs in the pastas column\n",
    "activitats_filtered['shared_id'] = activitats_filtered['activitat'].map(activitat_unique_id)\n",
    "\n",
    "# Save or display the updated activitats DataFrame\n",
    "activitats_filtered.to_csv('activitats_with_shared.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per últim separem per les cuatre aules de les quals tenim a disposició notes d'exàmens, i esborrem del general les que no pertanyen a cap d'aquestes aules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files created for each specified aula_id.\n"
     ]
    }
   ],
   "source": [
    "# Define the aula_id values to filter\n",
    "aula_ids = [87, 92, 143, 141]\n",
    "\n",
    "activitats_filtered = activitats_filtered[activitats_filtered['aula_id'].isin(aula_ids)]\n",
    "\n",
    "activitats_filtered.to_csv('activitats_with_shared.csv', index=False)\n",
    "# Loop through each aula_id, filter, and save as a new CSV file\n",
    "for aula_id in aula_ids:\n",
    "    # Filter activitats for the current aula_id\n",
    "    filtered_df = activitats_filtered[activitats_filtered['aula_id'] == aula_id]\n",
    "    \n",
    "    # Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(f'activitats_aula_{aula_id}.csv', index=False)\n",
    "\n",
    "print(\"CSV files created for each specified aula_id.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added lables for diferent types of exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "        \"(OPCIONAL)\": 3,\n",
    "\n",
    "    \"Problema\": 1,\n",
    "    \"Entrega Practica\": 2,\n",
    "    \"Entrega Pràctica\": 2,\n",
    "    \"Lliurament Practica\": 2,\n",
    "    \"Lliurament Pr�ctica\": 2,\n",
    "    \"Lliurament Pràctica\": 2,\n",
    "    \"Pr�ctica\": 2,\n",
    "    \"RECUPERACI�\": 3,\n",
    "    \"Recuperació\": 3,\n",
    "    \"RECUPERACIÓ\": 3,\n",
    "    \"Final FP\": 4,\n",
    "    \"Exercici\": 5,\n",
    "    # Add more keywords and labels as needed\n",
    "}\n",
    "\n",
    "# Function to check for keywords in each activitat entry and assign a label\n",
    "def label_activity(activitat):\n",
    "    for keyword, label in keywords.items():\n",
    "        if keyword in activitat:\n",
    "            return label\n",
    "    return 0  # Default label if no keywords match\n",
    "\n",
    "# Apply the function to create a new 'label' column\n",
    "activitats_filtered['label'] = activitats_filtered['activitat'].apply(label_activity)\n",
    "activitats_filtered.to_csv('activitats_with_shared.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from mamba_ssm import Mamba\n",
    "\n",
    "batch, length, dim = 2, 64, 16\n",
    "model = Mamba(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "    d_model=dim, # Model dimension d_model\n",
    "    d_state=16,  # SSM state expansion factor\n",
    "    d_conv=4,    # Local convolution width\n",
    "    expand=2,    # Block expansion factor\n",
    ").to(\"cuda\")\n",
    "y = model(x)\n",
    "assert y.shape == x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rectangles_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
